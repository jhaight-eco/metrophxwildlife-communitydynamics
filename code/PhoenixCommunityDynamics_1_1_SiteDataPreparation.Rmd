---
title: "Metro Phoenix Wildlife Study - Community Dynamics - Site Data Preparation"
author: "Jeffrey Haight"
date: "`r Sys.Date()`"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)

```

```{r clear the environment, include = FALSE}
rm(list = ls())
gc()
```


```{r packages, warning=FALSE, echo = FALSE, message = FALSE}
# load packages
library(dplyr)   # for data reshaping
library(tidyverse)
library(hydroTSM)  # this should make working with the daily precipitation data a lot easier

# packages for spatial analysis
library(sp)
library(spdplyr)
library(raster)
library(rgdal)
library(rgeos)
#library(spatstat)   # for point pattern analysis
#library(spdep)      # for spatial autocorrelation
library(landscapemetrics)    # for FRAGSTATS metrics

# visualization packages
library(ggplot2)
library(ggridges)
library(ggmap)    # for getting basemaps
library(tmap)
library(RColorBrewer)
library(viridis)
library(leaflet)
library(ggcorrplot)
library(GGally)
library(plotly)
```


```{r Spatial projections, include = FALSE}
# the projection used for most CAP LTER data, including the NAIP imagery
prj.cap <- "+proj=utm +zone=12 +ellps=GRS80 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_defs"
      
# the projection used for the NLCD
prj.aea.wgs84 <- "+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=WGS84 +towgs84=0,0,0,-0,-0,-0,0 +units=m +no_defs"

# the projection used for the WUI dataset (2010 Census blocks)
prj.aea.nad83 <- "+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"
```


# Spatial Data Import
```{r Data Import, echo = FALSE}
# Spatial data from which to extract metrics
  # 30 m Land Cover (NLCD 2016)
      # All of the contiguous US
      nlcd.full <- raster("C:/Research/landcover/NLCD_2019_Land_Cover_CONUS/nlcd_2019_land_cover_l48_20210604.img")
  
  # 1 m Land Cover (CAP LTER NAIP land cover)
      naip2015 <- raster("C:/Research/urban/CAPLTER/data/spatial/NAIP2015/685_land_cover_1m_2015.tif")
      
  # % impervious surface
      #is16 <-raster("C:/Research/landcover/nlcd_2016_impervious_l48/nlcd_2016_impervious_l48_20210604.img")
      is19 <- raster("C:/Research/landcover/nlcd_2019_impervious_l48/nlcd_2019_impervious_l48_20210604.img")
      
  
  # Populatin density within 1000 m
      popden1000 <- raster("C:/Research/urban/CAPLTER/data/spatial/WUI/cb_popden2010_buffer1000m.tif")

# Spatial data for the study area and sites
  # CAP LTER Study Boundary
      cap <- readOGR("C:/Research/urban/CAPLTER/data/sites/cap_boundary_Project", layer = "cap_boundary_Project") %>%
        spTransform(prj.aea.wgs84)
  
  # Maricopa County
      # Census 2010 block groups
      maricopa.bg <- readOGR("C:/Research/urban/CAPLTER/data/spatial/Census2010/tl_2010_04013_bg10.shp") 
      # dissolve the block groups and reproject to AEA 84 (same as the NLCD)
      maricopa <- spTransform(aggregate(maricopa.bg), prj.aea.wgs84)     
  
      
  # Survey Points
      list.files("C:/Research/urban/CAPLTER/data/sites/PWS/cam")
      cam <-readOGR(dsn = "C:/Research/urban/CAPLTER/data/sites/PWS/cam", layer = "pts_wildlife_cameras")  #, crs(naip2015)
      colnames(cam@data)[18] <- "urb1km_10"
      
      cam.nlcd <- spTransform(cam, crs(is19))
      
    
    
```

# Extract Site Covariates
### NDVI
This NDVI was calculated in Google Earth Engine based on Landsat 8 imagery surface reflectance. 
```{r}
# projecting each of these takes a minute, but it's necessary for the extents to overlap
# this is the most time consuming part of extracting the NDVI values
Sys.time()
ndvi_wd <- projectRaster(raster("C:/Research/urban/CAPLTER/data/spatial/NDVI/MPWS/NDVI_WarmDry2019.tif"), crs = crs(cam.nlcd))

ndvi_ww <- projectRaster(raster("C:/Research/urban/CAPLTER/data/spatial/NDVI/MPWS/NDVI_WarmWet2019.tif"), crs = crs(cam.nlcd))

ndvi_cw <- projectRaster(raster("C:/Research/urban/CAPLTER/data/spatial/NDVI/MPWS/NDVI_CoolWet2020.tif"), crs = crs(cam.nlcd))
Sys.time()
```

A 1000-m moving window was used to produce the following smoothed rasters of mean NDVI within 1000 m
```{r}
ndvi1000_wd <- raster("C:/Research/urban/CAPLTER/data/spatial/NDVI/MPWS/NDVI_WarmDry2019_1000m.tif") 
ndvi1000_ww <- raster("C:/Research/urban/CAPLTER/data/spatial/NDVI/MPWS/NDVI_WarmWet2019_1000m.tif")
ndvi1000_cw <- raster("C:/Research/urban/CAPLTER/data/spatial/NDVI/MPWS/NDVI_CoolWet2020_1000m.tif")

#cam@data$ndvi1km_wd <- extract(ndvi_wd, spTransform(cam, crs(ndvi1000_wd)))
```

But, it also wouldn't take much to use the NDVI rasters to calculate means at multiple scales
```{r warm dry season NDVI}
sites <- cam.nlcd #spTransform(cam.nlcd, crs(ndvi_wd))


# Warm-Dry 100 m
    ndvi <- rep(NA, nrow(sites))
    ndvi_sd <- rep(NA, nrow(sites))
    buffer <- 100   # choose the buffer size, in meters
    for(i in 1:length(sites)){
      pt <- sites[i,]                                         # select a point
      buff <- gBuffer(pt, width = buffer, quadsegs = 25)      # create buffer around the point
      landscape <- ndvi_wd %>%    # crop it to the local 'landscape'
          crop(extent(buff)) %>%
          mask(buff)
      ndvi[i] <- extract(landscape, buff, fun = mean, na.rm = TRUE)  # extract the mean
      ndvi_sd[i] <- extract(landscape, buff, fun = sd, na.rm = TRUE)  # extract the standard deviation (vegetation heterogeneity)
      #plot(landscape); plot(pt, add = TRUE)
    }
    cam@data$ndvi_wd100m <- ndvi
    cam@data$ndvi_sd_wd100m <- ndvi_sd
    Sys.time()

    

# Warm-Dry 1000 m
    ndvi <- rep(NA, nrow(sites))
    ndvi_sd <- rep(NA, nrow(sites))
    buffer <- 1000   # choose the buffer size, in meters
    for(i in 1:length(sites)){
      pt <- sites[i,]                                         # select a point
      buff <- gBuffer(pt, width = buffer, quadsegs = 25)      # create buffer around the point
      landscape <- ndvi_wd %>%    # crop it to the local 'landscape'
          crop(extent(buff)) %>%
          mask(buff)
      ndvi[i] <- extract(landscape, buff, fun = mean, na.rm = TRUE)  # extract the mean
      ndvi_sd[i] <- extract(landscape, buff, fun = sd, na.rm = TRUE)  # extract the standard deviation (vegetation heterogeneity)
      #plot(landscape); plot(pt, add = TRUE)
    }
    cam@data$ndvi_wd1km <- ndvi
    cam@data$ndvi_sd_wd1km <- ndvi_sd
    Sys.time()

    
# Warm-Dry 5000 m
    ndvi <- rep(NA, nrow(sites))
    ndvi_sd <- rep(NA, nrow(sites))
    buffer <- 5000   # choose the buffer size, in meters
    for(i in 1:length(sites)){
      pt <- sites[i,]                                         # select a point
      buff <- gBuffer(pt, width = buffer, quadsegs = 25)      # create buffer around the point
      landscape <- ndvi_wd %>%    # crop it to the local 'landscape'
          crop(extent(buff)) %>%
          mask(buff)
      ndvi[i] <- extract(landscape, buff, fun = mean, na.rm = TRUE)  # extract the mean
      ndvi_sd[i] <- extract(landscape, buff, fun = sd, na.rm = TRUE)  # extract the standard deviation (vegetation heterogeneity)
      #plot(landscape); plot(pt, add = TRUE)
    }
    cam@data$ndvi_wd5km <- ndvi
    cam@data$ndvi_sd_wd5km <- ndvi_sd
    Sys.time()

  
```

```{r warm wet season NDVI}
sites <- cam.nlcd #spTransform(cam.nlcd, crs(ndvi_wd))


# Warm-Wet 100 m
    ndvi <- rep(NA, nrow(sites))
    ndvi_sd <- rep(NA, nrow(sites))
    buffer <- 100   # choose the buffer size, in meters
    for(i in 1:length(sites)){
      pt <- sites[i,]                                         # select a point
      buff <- gBuffer(pt, width = buffer, quadsegs = 25)      # create buffer around the point
      landscape <- ndvi_ww %>%    # crop it to the local 'landscape'
          crop(extent(buff)) %>%
          mask(buff)
      ndvi[i] <- extract(landscape, buff, fun = mean, na.rm = TRUE)  # extract the mean
      ndvi_sd[i] <- extract(landscape, buff, fun = sd, na.rm = TRUE)  # extract the standard deviation (vegetation heterogeneity)
      #plot(landscape); plot(pt, add = TRUE)
    }
    cam@data$ndvi_ww100m <- ndvi
    cam@data$ndvi_sd_ww100m <- ndvi_sd
    Sys.time()


# Warm-Wet 1000 m
    ndvi <- rep(NA, nrow(sites))
    ndvi_sd <- rep(NA, nrow(sites))
    buffer <- 1000   # choose the buffer size, in meters
    for(i in 1:length(sites)){
      pt <- sites[i,]                                         # select a point
      buff <- gBuffer(pt, width = buffer, quadsegs = 25)      # create buffer around the point
      landscape <- ndvi_ww %>%    # crop it to the local 'landscape'
          crop(extent(buff)) %>%
          mask(buff)
      ndvi[i] <- extract(landscape, buff, fun = mean, na.rm = TRUE)  # extract the mean
      ndvi_sd[i] <- extract(landscape, buff, fun = sd, na.rm = TRUE)  # extract the standard deviation (vegetation heterogeneity)
      #plot(landscape); plot(pt, add = TRUE)
    }
    cam@data$ndvi_ww1km <- ndvi
    cam@data$ndvi_sd_ww1km <- ndvi_sd
    Sys.time()

    
# Warm-Wet 5000 m
    ndvi <- rep(NA, nrow(sites))
    ndvi_sd <- rep(NA, nrow(sites))
    buffer <- 5000   # choose the buffer size, in meters
    for(i in 1:length(sites)){
      pt <- sites[i,]                                         # select a point
      buff <- gBuffer(pt, width = buffer, quadsegs = 25)      # create buffer around the point
      landscape <- ndvi_ww %>%    # crop it to the local 'landscape'
          crop(extent(buff)) %>%
          mask(buff)
      ndvi[i] <- extract(landscape, buff, fun = mean, na.rm = TRUE)  # extract the mean
      ndvi_sd[i] <- extract(landscape, buff, fun = sd, na.rm = TRUE)  # extract the standard deviation (vegetation heterogeneity)
      #plot(landscape); plot(pt, add = TRUE)
    }
    cam@data$ndvi_ww5km <- ndvi
    cam@data$ndvi_sd_ww5km <- ndvi_sd
    Sys.time()

```
```{r warm wet season NDVI}
sites <- cam.nlcd #spTransform(cam.nlcd, crs(ndvi_wd))


# Cool-Wet 100 m
    ndvi <- rep(NA, nrow(sites))
    ndvi_sd <- rep(NA, nrow(sites))
    buffer <- 100   # choose the buffer size, in meters
    for(i in 1:length(sites)){
      pt <- sites[i,]                                         # select a point
      buff <- gBuffer(pt, width = buffer, quadsegs = 25)      # create buffer around the point
      landscape <- ndvi_cw %>%    # crop it to the local 'landscape'
          crop(extent(buff)) %>%
          mask(buff)
      ndvi[i] <- extract(landscape, buff, fun = mean, na.rm = TRUE)  # extract the mean
      ndvi_sd[i] <- extract(landscape, buff, fun = sd, na.rm = TRUE)  # extract the standard deviation (vegetation heterogeneity)
      #plot(landscape); plot(pt, add = TRUE)
    }
    cam@data$ndvi_cw100m <- ndvi
    cam@data$ndvi_sd_cw100m <- ndvi_sd
    Sys.time()


# Cool-Wet 1000 m
    ndvi <- rep(NA, nrow(sites))
    ndvi_sd <- rep(NA, nrow(sites))
    buffer <- 1000   # choose the buffer size, in meters
    for(i in 1:length(sites)){
      pt <- sites[i,]                                         # select a point
      buff <- gBuffer(pt, width = buffer, quadsegs = 25)      # create buffer around the point
      landscape <- ndvi_cw %>%    # crop it to the local 'landscape'
          crop(extent(buff)) %>%
          mask(buff)
      ndvi[i] <- extract(landscape, buff, fun = mean, na.rm = TRUE)  # extract the mean
      ndvi_sd[i] <- extract(landscape, buff, fun = sd, na.rm = TRUE)  # extract the standard deviation (vegetation heterogeneity)
      #plot(landscape); plot(pt, add = TRUE)
    }
    cam@data$ndvi_cw1km <- ndvi
    cam@data$ndvi_sd_cw1km <- ndvi_sd
    Sys.time()

    
# Cool-Wet 5000 m
    ndvi <- rep(NA, nrow(sites))
    ndvi_sd <- rep(NA, nrow(sites))
    buffer <- 5000   # choose the buffer size, in meters
    for(i in 1:length(sites)){
      pt <- sites[i,]                                         # select a point
      buff <- gBuffer(pt, width = buffer, quadsegs = 25)      # create buffer around the point
      landscape <- ndvi_cw %>%    # crop it to the local 'landscape'
          crop(extent(buff)) %>%
          mask(buff)
      ndvi[i] <- extract(landscape, buff, fun = mean, na.rm = TRUE)  # extract the mean
      ndvi_sd[i] <- extract(landscape, buff, fun = sd, na.rm = TRUE)  # extract the standard deviation (vegetation heterogeneity)
      #plot(landscape); plot(pt, add = TRUE)
    }
    cam@data$ndvi_cw5km <- ndvi
    cam@data$ndvi_sd_cw5km <- ndvi_sd
    Sys.time()

```


### Precipitation & Temperature
#####  Data from the Maricopa County Flood Control District rainfall gages nearest to each camera site
```{r precip gage data}
# the site names with their nearest rainfall gage
gage <- read.csv("C:/Research/urban/CAPLTER/data/site_vars/cam/precip_nearest_cam_MCFCD/pts_cam_nearestgage.csv")
gage %>% filter(GageID == 67000)
gage$GageID <- as.factor(gage$GageID)

# the precip data
ppt <- read.csv("C:/Research/urban/CAPLTER/data/site_vars/cam/precip_nearest_cam_MCFCD/precip_MCFCD_10-2018_09-2020_nearestgages.csv")
ppt$date <- as.Date(ppt$date, format = "%m/%d/%Y")
ppt$GageID <- as.factor(ppt$GageID)

ppt


#?decompose
#daily2monthly(ppt, FUN=sum)

# set some date limits to the data
limits <- as.Date(c("2019-01-01", "2020-09-01"))


# join it with the site data
ppt.site <- left_join(gage, ppt, by = "GageID")
ppt.site  #%>% filter(GageID == 67000)

```

```{r}
ggplot(ppt.site, aes(x = date, y = rainfall_in, col = GageID)) +
  theme_classic()+
  geom_line()+
  scale_x_date(limits = limits, date_breaks = "1 month") +
  #scale_y_continuous(limits = c(-3, 15)) +
  #coord_cartesian(xlim = limits, ylim=c(0,0.25))+
  xlab("Date") + 
  ylab("Precipitation (Inches)")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ggplot(ppt.site, aes(x = date, y = rainfall_in, fill = GageID)) +
  theme_classic()+
  geom_bar(stat = "identity") +
  scale_x_date(limits = limits, date_breaks = "1 month") +
  #scale_y_continuous(limits = c(-3, 15)) +
  #coord_cartesian(xlim = limits, ylim=c(0,0.25))+
  xlab("Date") + 
  ylab("Precipitation (Inches)")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ggplot(ppt.site, aes(x = date, y = rainfall_in)) +   # , col = gageID
  theme_classic()+
  geom_smooth(se = FALSE, alpha = 0.2)+
  geom_point(alpha = 0.2)+
  scale_x_date(limits = limits, date_breaks = "1 month") +
  scale_y_continuous(limits = c(-3, 15)) +
  coord_cartesian(xlim = limits, ylim=c(0,0.25))+
  xlab("Date") + 
  ylab("Precipitation (Inches)")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


# average precip across the study area
ppt.reg <- ppt.site %>%
  group_by(date) %>%
  summarize(rf_in_meanarea = mean(rainfall_in))
ppt.reg

ggplot(ppt.reg, aes(x = date, y = rf_in_meanarea)) +   # , col = gageID
  theme_classic()+
  geom_smooth(se = FALSE, alpha = 0.2)+
  geom_point(alpha = 0.2)+
  scale_x_date(limits = limits, date_breaks = "1 month") +
  scale_y_continuous(limits = c(-3, 15)) +
  coord_cartesian(xlim = limits, ylim=c(0,1.1))+
  xlab("Date") + 
  ylab("Precipitation (Inches)")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ggplot(ppt.reg, aes(x = date, y = rf_in_meanarea)) +
  theme_classic()+
  geom_bar(stat = "identity") +
  scale_x_date(limits = limits, date_breaks = "1 month") +
  scale_y_continuous(limits = c(-3, 15)) +
  coord_cartesian(xlim = limits, ylim=c(0,1.1))+
  xlab("Date") + 
  ylab("Precipitation (Inches)")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

Based on the precipitation data, natural breaks between wet and dry seasons occur around:  
March 15th 2019 (start of the warm-dry season)  
July 20th 2019 (start of the warm-wet season)  
October 2019 (a relatively dry period, but still warm, so could be grouped with warm-wet)  
November 15th 2019 (start of the cool-wet)  
March 15th 2020 (start of the warm-dry again)  

From this, we will make our equal-sized seasons:  
Warm-Dry 2019 - April 15th to July 19th  
Warm-Wet 2019 - July 20th to October 23rd  
Cool-Wet 2019 - December 1st to March 5th  (2020 was a leap year)

```{r}

# total rainfall at each site during specific time periods
ppt.site %>%
      filter(date > "2019-03-15" & date <"2019-03-30") %>%
      group_by(site) %>%
      summarize(rainfall_in = sum(rainfall_in))

mean(ppt.site %>%
      filter(date > "2018-11-30" & date <"2019-04-01") %>%
      group_by(site) %>%
      summarize(rainfall_in = sum(rainfall_in)) %>% pull(rainfall_in))*25.4

mean(ppt.site %>%
      filter(date > "2019-06-30" & date <"2019-10-01") %>%
      group_by(site) %>%
      summarize(rainfall_in = sum(rainfall_in)) %>% pull(rainfall_in))*25.4

mean(ppt.site %>%
      filter(date > "2019-11-30" & date <"2020-04-01") %>%
      group_by(site) %>%
      summarize(rainfall_in = sum(rainfall_in)) %>% pull(rainfall_in))*25.4


# number of days in a particular season
ppt.site %>%
      filter(date > "2019-11-14" & date <"2020-02-28") %>%
      group_by(site) %>%
  nrow()/50


# add some of these as site variables
    # warm-dry season
    cam@data$ppt_wd <- ppt.site %>%
      filter(date > "2019-04-14" & date <"2019-07-20") %>%
      group_by(site) %>%
      summarize(rainfall_in = sum(rainfall_in)) %>% 
      pull(rainfall_in)*2.54  # convert to mm
    
    # warm-wet season
    cam@data$ppt_ww <- ppt.site %>%
      filter(date > "2019-07-19" & date <"2019-10-24") %>%
      group_by(site) %>%
      summarize(rainfall_in = sum(rainfall_in)) %>% 
      pull(rainfall_in)*2.54  # convert to mm
    
    # cool-wet season
    cam@data$ppt_cw <- ppt.site %>%
      filter(date > "2019-11-30" & date <"2020-03-06") %>%
      group_by(site) %>%
      summarize(rainfall_in = sum(rainfall_in)) %>% 
      pull(rainfall_in)*2.54  # convert to mm

    
```

### Remote-sensed climate data from NASA Daymet, retrieved via Google Earth Engine
```{r remote climate data}
clim <- read.csv("C:/Research/urban/CAPLTER/data/site_vars/cam/pts_camera_Daymet_1000_01dec18_31mar20.csv")
#clim

# convert the datetime column to a single date column
clim$date <- as.Date(clim$datetime, format =  "%m/%d/%Y %H:%M")


clim <- clim  %>%
  filter(between(date, as.Date('2018-12-01'), as.Date('2020-03-31'))) %>%
  arrange(site, date)

clim.wd <- clim %>%
  filter(between(date, as.Date('2019-04-15'), as.Date('2019-07-19'))) %>%
  arrange(site, date)

clim.ww <- clim %>%
  filter(between(date, as.Date('2019-07-20'), as.Date('2019-10-23'))) %>%
  arrange(site, date)

clim.cw <- clim %>%
  filter(between(date, as.Date('2019-12-01'), as.Date('2020-03-05'))) %>%
  arrange(site, date)



# add an "occasion" column. This will come in handy if daily occasions ends up not working in the model
# each dataframe needs to be already arranged by site, then date
clim.wd$occ16day  <- rep(rep(paste("o", 1:6, sep = ""), each = 16), 50)
clim.ww$occ16day  <- rep(rep(paste("o", 1:6, sep = ""), each = 16), 50)
clim.cw$occ16day  <- rep(rep(paste("o", 1:6, sep = ""), each = 16), 50)
clim.cw$occ16day  <- rep(rep(1:6, each = 16), 50)
```
```{r summarize total precip and average temp}
# for getting 
ppt.winter19 <- clim %>%
  filter(between(date, as.Date('2018-12-01'), as.Date('2019-03-31'))) %>%
  arrange(site, date) %>%
  group_by(date) %>%
  summarize(ppt_sitemean = mean(ppt, na.rm = T))
sum(ppt.winter19$ppt_sitemean)

ppt.monsoon19 <- clim %>%
  filter(between(date, as.Date('2019-07-01'), as.Date('2019-09-30'))) %>%
  arrange(site, date) %>%
  group_by(date) %>%
  summarize(ppt_sitemean = mean(ppt, na.rm = T))
sum(ppt.monsoon19$ppt_sitemean)

ppt.winter20 <- clim %>%
  filter(between(date, as.Date('2019-12-01'), as.Date('2020-03-31'))) %>%
  arrange(site, date )%>%
  group_by(date) %>%
  summarize(ppt_sitemean = mean(ppt, na.rm = T))
sum(ppt.winter20$ppt_sitemean)
```

```{r plot Daymet data}
# set some limits to the dates
limits <- as.Date(c("2018-12-01", "2020-03-31"))
limits.wd <- as.Date(c("2019-04-15", "2019-07-19"))
limits.ww <- as.Date(c("2019-07-20", "2019-10-23"))
limits.cw <- as.Date(c("2019-12-01", "2020-03-05"))


ppt.reg.DM <- clim %>%
  group_by(date) %>%
  summarize(ppt_sitemean = mean(ppt, na.rm = T))
ppt.reg.DM


tmax.reg.DM <- clim %>%
  group_by(date) %>%
  summarize(tmax_sitemean = mean(temp_max, na.rm = T))
tmax.reg.DM


ggplot(clim, aes(x = date, y = ppt)) +  
  theme_classic()+
  geom_smooth(se = FALSE, alpha = 0.2)+
  geom_point(alpha = 0.2)+
  scale_x_date(limits = limits, date_breaks = "1 month") +
  scale_y_continuous(limits = c(-3, 15)) +
  coord_cartesian(xlim = limits, ylim=c(0,5))+
  xlab("Date") + 
  ylab("Precipitation (mm)")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ggplot(ppt.reg.DM, aes(x = date, y = ppt_sitemean)) +
  theme_classic()+
  geom_bar(stat = "identity") +
  scale_x_date(limits = limits, date_breaks = "1 month") +
  scale_y_continuous(limits = c(-3, 15)) +
  coord_cartesian(xlim = limits, ylim=c(0,15))+
  xlab("Date") + 
  ylab("Precipitation (mm)")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


# Temperature 
ggplot() +  
  theme_classic()+
  geom_smooth(data = clim, aes(x = date, y = temp_max), se = FALSE, alpha = 0.2, col = "red4") +
  geom_point(data = clim, aes(x = date, y = temp_max), alpha = 0.1, col = "red4")+
  geom_smooth(data = clim, aes(x = date, y = temp_min), se = FALSE, alpha = 0.2, col = "blue4") +
  geom_point(data = clim, aes(x = date, y = temp_min), alpha = 0.1, col = "blue4")+
  scale_x_date(limits = limits, date_breaks = "1 month") +
  scale_y_continuous(limits = c(-3, 50)) +
  coord_cartesian(xlim = limits, ylim=c(0,50))+
  xlab("Date") + 
  ylab("Daily Temperature (C)")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ggplot() +  
  theme_classic()+
  geom_point(data = clim, aes(x = temp_min, y = temp_max, col = stratum), alpha = 0.1)+
  geom_smooth(data = clim, aes(x = temp_min, y = temp_max), se = FALSE, alpha = 0.2, method = "lm") +
  scale_x_continuous(limits = c(-3, 50)) +
  scale_y_continuous(limits = c(-3, 50)) +
  coord_cartesian(xlim = c(0,35), ylim=c(0,50))+
  xlab("Daily Minimum Temperature (C)") + 
  ylab("Daily Maximum Temperature (C)")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


ggplot() +
  theme_classic()+
  geom_smooth(data = tmax.reg.DM, aes(x = date, y = tmax_sitemean), se = FALSE, alpha = 0.2, col = "red4") +
  geom_point(data = tmax.reg.DM, aes(x = date, y = tmax_sitemean), alpha = 0.1, col = "red4")+
  scale_x_date(limits = limits, date_breaks = "1 month") +
  #scale_y_continuous(limits = c(-3, 15)) +
  coord_cartesian(xlim = limits, ylim=c(0,50))+
  xlab("Date") + 
  ylab("Daily Maximum Temperature (C)")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))



# Daily temperature difference
ggplot() +  
  theme_classic()+
  geom_smooth(data = clim, aes(x = date, y = (temp_max-temp_min)), se = FALSE, alpha = 0.2, col = "red4") +
  geom_point(data = clim, aes(x = date, y = (temp_max-temp_min), col = stratum), alpha = 0.1)+
  scale_x_date(limits = limits, date_breaks = "1 month") +
  scale_y_continuous(limits = c(-3, 50)) +
  coord_cartesian(xlim = limits, ylim=c(0,30))+
  xlab("Date") + 
  ylab("Daily Temperature Difference (C)")+ 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```
```{r gage vs remote sensed ppt}
ppt1 <- ppt.site %>%
  arrange(site, date) %>%
  filter(between(date, as.Date('2019-03-15'), as.Date('2020-02-27')))

ppt2 <- clim %>%
  arrange(site, date) %>%
  filter(between(date, as.Date('2019-03-15'), as.Date('2020-02-27')))

# correlation between rainfall measured at nearest rain gage and remote-sensed precipitation
cor(ppt1$rainfall_in, ppt2$ppt)
plot(ppt1$rainfall_in, ppt2$ppt)


```

```{r reformat climate data}
# Daily minimum temperature
(tmin.wd <- clim.wd %>% 
  select(site, date, temp_min) %>%
  pivot_wider(names_from = date, values_from = temp_min))

(tmin.ww <- clim.ww %>% 
  select(site, date, temp_min) %>%
  pivot_wider(names_from = date, values_from = temp_min))

(tmin.cw <- clim.cw %>% 
  select(site, date, temp_min) %>%
  pivot_wider(names_from = date, values_from = temp_min))

# Daily maximum temperature
(tmax.wd <- clim.wd %>% 
  select(site, date, temp_max) %>%
  pivot_wider(names_from = date, values_from = temp_max))

(tmax.ww <- clim.ww %>% 
  select(site, date, temp_max) %>%
  pivot_wider(names_from = date, values_from = temp_max))

(tmax.cw <- clim.cw %>% 
  select(site, date, temp_max) %>%
  pivot_wider(names_from = date, values_from = temp_max))

# Daily precipitation
(ppt.wd <- clim.wd %>% 
  select(site, date, ppt) %>%
  pivot_wider(names_from = date, values_from = ppt))

(ppt.ww <- clim.ww %>% 
  select(site, date, ppt) %>%
  pivot_wider(names_from = date, values_from = ppt))

(ppt.cw <- clim.cw %>% 
  select(site, date, ppt) %>%
  pivot_wider(names_from = date, values_from = ppt))


# summarize the data by sampling occasions, if desired
clim.cw %>%
  group_by(site, occ16day) %>%
  summarize(ppt = sum(ppt, na.rm = TRUE)) %>%
  pivot_wider(names_from = occ16day, values_from = ppt)
#write.csv(tmin.wd, "", row.names = FALSE)

# add the DayMet data to the main dataframe
cam@data$tmin_wd_DM <- apply(tmin.wd[,-1], c(1), function(x) mean(x, na.rm=TRUE))
cam@data$tmin_ww_DM <- apply(tmin.ww[,-1], c(1), function(x) mean(x, na.rm=TRUE))
cam@data$tmin_cw_DM <- apply(tmin.cw[,-1], c(1), function(x) mean(x, na.rm=TRUE))

cam@data$tmax_wd_DM <- apply(tmax.wd[,-1], c(1), function(x) mean(x, na.rm=TRUE))
cam@data$tmax_ww_DM <- apply(tmax.ww[,-1], c(1), function(x) mean(x, na.rm=TRUE))
cam@data$tmax_cw_DM <- apply(tmax.cw[,-1], c(1), function(x) mean(x, na.rm=TRUE))

cam@data$ppt_wd_DM <- apply(ppt.wd[,-1], c(1), function(x) sum(x, na.rm=TRUE))
cam@data$ppt_ww_DM <- apply(ppt.ww[,-1], c(1), function(x) sum(x, na.rm=TRUE))
cam@data$ppt_cw_DM <- apply(ppt.cw[,-1], c(1), function(x) sum(x, na.rm=TRUE))



```

```{r export the climate data}
# daily climate
write.csv(ppt.wd, "./data/2_cov_site/ppt/ppt_daily_season1_warmdry.csv", row.names = FALSE)
write.csv(ppt.ww, "./data/2_cov_site/ppt/ppt_daily_season2_warmwet.csv", row.names = FALSE)
write.csv(ppt.cw, "./data/2_cov_site/ppt/ppt_daily_season3_coldwet.csv", row.names = FALSE)

write.csv(tmax.wd, "./data/2_cov_site/tmax/tmax_daily_season1_warmdry.csv", row.names = FALSE)
write.csv(tmax.ww, "./data/2_cov_site/tmax/tmax_daily_season2_warmwet.csv", row.names = FALSE)
write.csv(tmax.cw, "./data/2_cov_site/tmax/tmax_daily_season3_coldwet.csv", row.names = FALSE)

write.csv(tmin.wd, "./data/2_cov_site/tmin/tmin_daily_season1_warmdry.csv", row.names = FALSE)
write.csv(tmin.ww, "./data/2_cov_site/tmin/tmin_daily_season2_warmwet.csv", row.names = FALSE)
write.csv(tmin.cw, "./data/2_cov_site/tmin/tmax_daily_season3_coldwet.csv", row.names = FALSE)


#read.csv("./data/2_cov_site/tmin/tmax_daily_season3_coldwet.csv") # test importing the exported data

# Climate averaged by week/sampling occasion?
```


### NAIP 2015 Land Cover Proportions
```{r}
urb100m <- raster("C:/Research/urban/CAPLTER/data/spatial/NAIP2015/urban/NAIP2015_urban_prop100m.tif")
urb1km <- raster("C:/Research/urban/CAPLTER/data/spatial/NAIP2015/urban/NAIP2015_urban_prop1000m.tif")
veg100m <- raster("C:/Research/urban/CAPLTER/data/spatial/NAIP2015/veg/NAIP2015_woodyveg_prop100m.tif")
veg1km <- raster("C:/Research/urban/CAPLTER/data/spatial/NAIP2015/veg/NAIP2015_woodyveg_prop1000m.tif")
#ag100m <- raster("C:/Research/urban/CAPLTER/data/spatial/NAIP2015/veg/NAIP2015_ag_prop100m.tif")
#ag1km <- raster("C:/Research/urban/CAPLTER/data/spatial/NAIP2015/veg/NAIP2015_ag_prop1000m.tif")

#plot(urb100m); plot(spTransform(cam, crs(urb100m)), add = T)

# extract the values
cam@data$urb100m_15 <- extract(urb100m, spTransform(cam, crs(urb100m)))
cam@data$urb1km_15 <- extract(urb1km, spTransform(cam, crs(urb1km)))
cam@data$veg100m_15 <- extract(veg100m, spTransform(cam, crs(veg100m)))
cam@data$veg1km_15 <- extract(veg1km, spTransform(cam, crs(veg1km)))

plot(cam$urb100m_15, cam$urb1km_15)
plot(cam$veg100m_15, cam$veg1km_15)

plot(cam$urb100m_15, cam$veg100m_15)  # cor = 0.28
plot(cam$urb1km_15, cam$veg1km_15)    # cor = 0.52. tree cover is positively associated with urbanization if anything
```



### Impervious Surface Cover (NLCD)
```{r extract impervious surface percentage}
#plot(is, add = TRUE)#; plot(cam.nlcd, add = TRUE)

sites <- cam.nlcd

is.site <- data.frame(
  sites@data,
  "imp100m" = rep(NA, nrow(sites@data)),
  "imp1km" = rep(NA, nrow(sites@data)),
  "imp5km" = rep(NA, nrow(sites@data))
)

i <- 50          # select the site


# Takes about 8 minutes
Sys.time()

# 100 m
    buffer <- 100   # choose the buffer size, in meters
    for(i in 1:length(sites)){
      pt <- sites[i,]                                         # select a point
      buff <- gBuffer(pt, width = buffer, quadsegs = 25)      # create buffer around the point. This determines the size of the landscape
      
      landscape <- is19 %>%
          crop(extent(buff)) %>%
          mask(buff)
      
      is.site$imp100m[i] <- extract(landscape, buff, fun = mean, na.rm = TRUE)
      
      #plot(landscape); plot(pt, add = TRUE)
      #print(i)
    }
Sys.time()

# 1000 m
    buffer <- 1000   # choose the buffer size, in meters
    for(i in 1:length(sites)){
      pt <- sites[i,]                                         # select a point
      buff <- gBuffer(pt, width = buffer, quadsegs = 25)      # create buffer around the point. This determines the size of the landscape
      
      landscape <- is19 %>%
          crop(extent(buff)) %>%
          mask(buff)
      
      is.site$imp1km[i] <- extract(landscape, buff, fun = mean, na.rm = TRUE)
      
      #plot(landscape); plot(pt, add = TRUE)
      #print(i)
    }
Sys.time()

# 5000 m
    buffer <- 5000   # choose the buffer size, in meters
    for(i in 1:length(sites)){
      pt <- sites[i,]                                         # select a point
      buff <- gBuffer(pt, width = buffer, quadsegs = 25)      # create buffer around the point. This determines the size of the landscape
      
      landscape <- is19 %>%
          crop(extent(buff)) %>%
          mask(buff)
      
      is.site$imp5km[i] <- extract(landscape, buff, fun = mean, na.rm = TRUE)
      
      #plot(landscape); plot(pt, add = TRUE)
      #print(i)
    }
Sys.time()

is.site <- is.site %>%
  dplyr::select(c(site, imp100m, imp1km, imp5km))


plot(is.site$imp100m, is.site$imp1km)
plot(is.site$imp1km, is.site$imp5km)
plot(is.site$imp100m, is.site$imp5km)

cor(is.site$imp100m, is.site$imp1km)
cor(is.site$imp1km, is.site$imp5km)
cor(is.site$imp100m, is.site$imp5km)

is.site

cam@data$imp100m <- is.site$imp100m
cam@data$imp1km <- is.site$imp1km
cam@data$imp5km <- is.site$imp5km

```

##### Human Population Density
```{r}
# rasterized population density at the census block level

```


##### NLCD Landscape Metrics


Store data for a single metric within a 2D matrix (Sites X Metrics)
```{r}
# Choose the buffer/landscape size that you will use
buffers <- c(100, 1000, 5000)

# Choose the set of points you are assessing
sites <- cam.nlcd

# Specify the number of sites
nsite <- nrow(sites)
#nbuff <- length(buffers)

# Land cover composition metrics (class-level)
#  we will use 7 different land cover classes representing distinct habitat types
metrics_lc <- array(0, dim = c(nsite, 7, length(buffers)))  
colnames(metrics_lc) <- c("water",  
                            "dev",
                            "forest",
                            "shrub",
                            "herb",
                            "ag",
                            "wetland"
                            )

# Landscape heterogeneity metrics (compositional and configurational)
# Citations for these: Reynolds et al. 2017
metrics_lsm <- array(0, dim = c(nsite, 10, length(buffers)))  # make room for at at least 10 metrics
#dimnames(metrics_lsm)[2] <- c("mpa", "pd", "ed", "cohesion", "cohesion")
```

```{r}
sites <- cam.nlcd


#k <- 1
#i <- 4


for(k in 1:length(buffers)){
  for(i in 1:nsite){
  pt <- sites[i,]                                         # select a point
    buff <- gBuffer(pt, width = buffers[k], quadsegs = 25)      # Create buffer around the point
    #plot(buff); plot(pt, add = TRUE)
    
    ls_pre <- nlcd.full %>%
      crop(extent(buff)) %>%
      mask(buff)
    
    
    # Reclassify, setting all the natural land cover types to 20
    m <- c(11, 10,  # combine water and snow
           12, 10,  
           21, 20, # combined all developed types
           22, 20, 
           23, 20,
           24, 20, 
           41, 40, # combine all forest habitat types into one
           42, 40, 
           43, 40, 
           #52, 40, 
           #71, 40,
           #90, 40, 
           95, 90,  # combine the wetland types into one (90)
           81, 80,  # combine ag
           82, 80
           # keep the natural land cover types separate
       )
    rcmat <- matrix(m, ncol = 2, byrow = TRUE)
    
    ls <- reclassify(ls_pre, rcmat)
    
    
    # Landscape-level heterogeneity metrics
    metrics_lsm[i,1,k] <- lsm_l_area_mn(ls)$value   # Mean patch size/area (land cover group), in hectares
    metrics_lsm[i,2,k] <- lsm_l_pd(ls)$value        # Patch density
    metrics_lsm[i,3,k] <- lsm_l_ed(ls)$value        # Edge density 
    metrics_lsm[i,4,k] <- lsm_l_cohesion(ls)$value  # Patch cohesion index (aggregation metric)
    metrics_lsm[i,5,k] <- lsm_l_prd(ls)$value       # Patch richness density (diversity metric)
    metrics_lsm[i,6,k] <- lsm_l_shdi(ls)$value      # Shannon's index for patch diversity
    
    # Class-level metrics
    ca <- lsm_c_ca(ls_pre)        
    
    
    # plot(ls); plot(pt, add = T)   # plot (very optional)
    
    # Proportional area of each land cover class for each 
        # filter out the the data for each metric
        # convert from hectares to m^2 and calculate cover proportion based on buffer (10000 m^2/hectare / pi*r^2 square meters)
        # add to original array/matrix only if there is a value for that land cover class to add]
        
        # Open water, ice, and snow
        lsm_type <- ca %>%                               
          filter(class == 10)
        if(length(lsm_type$value) > 0){
            metrics_lc[i,1,k] <- lsm_type$value/sum(ca$value)
        }
        
        # repeat for each land cover class
        
        
        # Developed, all densities
        lsm_type <- ca %>%                              
          filter(class == 20)
        if(length(lsm_type$value) > 0){
            metrics_lc[i,1,k] <- lsm_type$value/sum(ca$value)
        }
        
        # Barren land (rock/sand/clay)
        lsm_type <- ca %>%                              
          filter(class == 31)
        if(length(lsm_type$value) > 0){
            metrics_lc[i,2,k] <- lsm_type$value/sum(ca$value)
        }
        
        # Forest
        lsm_type <- ca %>%                              
          filter(class == 40)
        if(length(lsm_type$value) > 0){
            metrics_lc[i,3,k] <- lsm_type$value/sum(ca$value)
        }
        
        # Shrubland
        lsm_type <- ca %>%                              
          filter(class == 52)
        if(length(lsm_type$value) > 0){
            metrics_lc[i,4,k] <- lsm_type$value/sum(ca$value)
        }
        
        # Grassland
        lsm_type <- ca %>%                              
          filter(class == 71)
        if(length(lsm_type$value) > 0){
            metrics_lc[i,5,k] <- lsm_type$value/sum(ca$value)
        }
        
        # Agriculture (pasture, hay, and cultivated crops)
        lsm_type <- ca %>%                              
          filter(class == 80)
        if(length(lsm_type$value) > 0){
            metrics_lc[i,6,k] <- lsm_type$value/sum(ca$value)
        }
        
        # Wetland
        lsm_type <- ca %>%                              
          filter(class == 90)
        if(length(lsm_type$value) > 0){
            metrics_lc[i,7,k] <- lsm_type$value/sum(ca$value)
        }
        
        
    # Class-level metrics
    #mpa <- lsm_c_area_mn(ls)   # Mean patch size/area for each class (land cover group), in hectares
    #pd <- lsm_c_pd(ls)         # Patch density for each class
    #ed <- lsm_c_ed(ls)         # Edge density for each class
    #enn <- lsm_c_enn_mn(ls)   # Mean Euclidean nearest-neighbor distance ('overall patch isolation')
    
    
        # Mean patch area for the natural patches
        #lsm_type <- mpa %>%                               
        #  filter(class == 40)
        #if(length(lsm_type$value) > 0){
        #    metrics_lsm[i,1] <- lsm_type$value
        #}
        
    
    
    #plot(ls); plot(pt, add = T)   # plot (very optional)
    
    #print(i)
    #print(sites[i,]$site)
  }
  print(paste(buffers[k], "m buffer complete", sep = ""))
}

# quick comparisons with 2010 NAIP LC impervious surfaces
  # not much of a trend with mean patch area. Slighly higher at urban gradient extremes though
  plot(cam@data$urb1km_10, metrics_lsm[,1,2])
  # Patch and edge density are correlated, both with a peak at moderate urbanization
  plot(cam@data$urb1km_10, metrics_lsm[,2,2])
  plot(cam@data$urb1km_10, metrics_lsm[,3,2])
  
  plot(cam@data$urb1km_10, metrics_lsm[,4,2])
  plot(cam@data$urb1km_10, metrics_lsm[,5,2])
  
  # Shannon Index (compositional diversity) shows clear peak in moderately urban areas
  plot(cam@data$urb1km_10, metrics_lsm[,6,2])  
  
  
  # Mean patch area (configurational)
  cam@data$mpa100m <- metrics_lsm[,1,1]
  cam@data$mpa1km <- metrics_lsm[,1,2]
  cam@data$mpa5km <- metrics_lsm[,1,3]
  
  # Patch Density (configurational)
  cam@data$pd100m <- metrics_lsm[,2,1]
  cam@data$pd1km <- metrics_lsm[,2,2]
  cam@data$pd5km <- metrics_lsm[,2,3]
  
  # Edge Density (configurational)
  cam@data$ed100m <- metrics_lsm[,3,1]
  cam@data$ed1km <- metrics_lsm[,3,2]
  cam@data$ed5km <- metrics_lsm[,3,3]
  
  # Patch cohesion index (configurational)
  cam@data$coh100m <- metrics_lsm[,4,1]
  cam@data$coh1km <- metrics_lsm[,4,2]
  cam@data$coh5km <- metrics_lsm[,4,3]
  
  # Patch richness density (compositional)
  cam@data$prd100m <- metrics_lsm[,5,1]
  cam@data$prd1km <- metrics_lsm[,5,2]
  cam@data$prd5km <- metrics_lsm[,5,3]
  
  # Shannon Diversity Index (compositional diversity)
  cam@data$sdhi100m <- metrics_lsm[,6,1]
  cam@data$sdhi1km <- metrics_lsm[,6,2]
  cam@data$sdhi5km <- metrics_lsm[,6,3]
  
```





# Assemble and export the site data
```{r}
data.site <- cam@data

(data.site <- data.site %>%
  dplyr::select(-c(e_bat_win, n_bat_win, e_bat_sum, n_bat_sum, date_start, date_end))
  )

write.csv(data.site, "./data/2_cov_site/covariates_50camsite.csv")
```

```{r}
# reshape to have all the seasons as a factor (keep it as an integer for now)
data.site$season <- rep("Season", nrow(data.site))
data.site$season_factor <- rep(1, nrow(data.site))


data.site.wd <- data.site %>%
  dplyr::select(-c(
    ndvi_ww100m, ndvi_ww1km, ndvi_ww5km,
    ndvi_sd_ww100m, ndvi_sd_ww1km, ndvi_sd_ww5km,
    ndvi_cw100m, ndvi_cw1km, ndvi_cw5km,
    ndvi_sd_cw100m, ndvi_sd_cw1km, ndvi_sd_cw5km,
    ppt_ww, ppt_cw,
    tmin_ww_DM, tmax_ww_DM, ppt_ww_DM,
    tmin_cw_DM, tmax_cw_DM, ppt_cw_DM))
colnames(data.site.wd)[13:22] <- c("ndvi_100m", "ndvi_sd_100m", "ndvi_1km", "ndvi_sd_1km", "ndvi_5km","ndvi_sd_5km", "ppt", "tmin", "tmax","ppt_DM")
data.site.wd$season <- "Warm-Dry"
data.site.wd$season_factor <- 1
data.site.wd

data.site.ww <- data.site %>%
  dplyr::select(-c(
    ndvi_wd100m, ndvi_wd1km, ndvi_wd5km,
    ndvi_sd_wd100m, ndvi_sd_wd1km, ndvi_sd_wd5km,
    ndvi_cw100m, ndvi_cw1km, ndvi_cw5km,
    ndvi_sd_cw100m, ndvi_sd_cw1km, ndvi_sd_cw5km,
    ppt_wd, ppt_cw,
    tmin_wd_DM, tmax_wd_DM, ppt_wd_DM,
    tmin_cw_DM, tmax_cw_DM, ppt_cw_DM))
colnames(data.site.ww)[13:22] <- c("ndvi_100m", "ndvi_sd_100m", "ndvi_1km", "ndvi_sd_1km", "ndvi_5km","ndvi_sd_5km", "ppt", "tmin", "tmax","ppt_DM")
data.site.ww$season <- "Warm-Wet"
data.site.ww$season_factor <- 2
data.site.ww

data.site.cw <- data.site %>%
  dplyr::select(-c(
    ndvi_wd100m, ndvi_wd1km, ndvi_wd5km,
    ndvi_sd_wd100m, ndvi_sd_wd1km, ndvi_sd_wd5km,
    ndvi_ww100m, ndvi_ww1km, ndvi_ww5km,
    ndvi_sd_ww100m, ndvi_sd_ww1km, ndvi_sd_ww5km,
    ppt_wd, ppt_ww,
    tmin_wd_DM, tmax_wd_DM, ppt_wd_DM,
    tmin_ww_DM, tmax_ww_DM, ppt_ww_DM))
colnames(data.site.cw)[13:22] <- c("ndvi_100m", "ndvi_sd_100m", "ndvi_1km", "ndvi_sd_1km", "ndvi_5km","ndvi_sd_5km", "ppt", "tmin", "tmax","ppt_DM")
data.site.cw$season <- "Cool-Wet"
data.site.cw$season_factor <- 3
data.site.cw


data.site.season <- bind_rows(data.site.wd, data.site.ww, data.site.cw)
data.site.season$season_factor
data.site.season


write.csv(data.site.season, "./data/2_cov_site/covariates_50camsite_byseason.csv")
```



